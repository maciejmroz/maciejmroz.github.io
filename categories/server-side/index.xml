<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Maciej Mróz Personal Blog</title>
    <link>/categories/server-side/index.xml</link>
    <description>Recent content on Maciej Mróz Personal Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="/categories/server-side/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Beyond virtualization</title>
      <link>/2015/01/01/beyond-virtualization/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>/2015/01/01/beyond-virtualization/</guid>
      <description>&lt;p&gt;I guess it&amp;rsquo;s time to sum up recent trends in how we build, deploy, and operate complex server side software. Virtualization and cloud computing have been with us for quite a while but right now the era of containers is coming, with entire Docker ecosystem paving the way. You might want to ask a very valid question: &amp;ldquo;What&amp;rsquo;s in it for me?&amp;rdquo; :) I will focus on business implications of the technology. But let&amp;rsquo;s set the context first.&lt;/p&gt;

&lt;p&gt;The explosion of cloud computing in recent years literally changed the way we think. Well, you probably could treat Amazon EC2 instances as if they were ordinary machines, but &amp;ldquo;in the cloud&amp;rdquo;. That of course would be &lt;strong&gt;totally&lt;/strong&gt; missing the point. The key advantages of cloud computing are on the intersection of operations, software architecture and development - these cannot be realized without moving to true DevOps. Trying to slap &amp;ldquo;cloud computing&amp;rdquo; sticker on top of existing organization with IT/Operations/Development (add more if needed to fit your case) silos will not give anyone much value. Once you change your approach, you suddenly get the true benefits:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Shorter cycle time from concept to delivering customer value&lt;/li&gt;
&lt;li&gt;Ability to to a lot more ad-hoc without unnecessary risk&lt;/li&gt;
&lt;li&gt;Resilient and scalable application architecture - one that&amp;rsquo;s flexible and evolving, not set in stone&lt;/li&gt;
&lt;li&gt;Reduced TCO thanks to automation, completely new usage patterns (i.e. instance that runs once a day for an hour) and services that cloud computing provider can operate way more efficiently than everyone else&lt;/li&gt;
&lt;li&gt;If everything else fails, ability to brute force your way out of many problems :)
The real cloud computing usage scenarios could look like this:&lt;/li&gt;
&lt;li&gt;The developer spins up new game instance because the team anticipates that the changes deployed just minutes ago will require more processing power. It happens in less than five minutes, instance is automatically put in proper security group, attached to load balancer (if necessary), tagged, monitoring is set up so that any problems with the instance are escalated to the team that launched it, and serving traffic! By the way, instance is based on a machine image that was generated automatically by Jenkins job triggered in the morning by change to the Git repository - few hours earlier someone found and fixed race condition in the gaming platform. All with single click or call of a command line.&lt;/li&gt;
&lt;li&gt;An analyst spins up an database instance with the last snapshot of production data, runs some very expensive SQL query, then shuts it down. All happening without any disruption to production service, at very low infrastructure cost, without bothering anyone. CEO gets the report he ordered a lot quicker than expected :)&lt;/li&gt;
&lt;li&gt;We get huge traffic spike on some of our smaller apps - this time somebody on the team actually makes decision to move to bigger instance type and spins up 3 larger instances, waits till they start serving traffic, then stops 4 smaller ones. Because of underlying automation, the new instances are automatically spread across availability zones. All this happens without any disruption to the service.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All of these scenarios, and a lot more, could happen at my company. In fact, they happen all the time, sometimes in parallel. To us these are just events. Not issues, emergencies, or disasters, but events. Extensive planning, overprovisioning, delays, service disruptions &amp;hellip; with the right mindset, you no longer have to worry about these and can focus on solving other problems. At least most of the time, obviously it&amp;rsquo;s not always perfect and rosy :) Bottom line: once you truly embrace cloud computing, the value is huge. If we can do all this stuff, why are people so exctited about using containers instead of just spinning up VMs like we do now?  Here we come to the hard part, because if you are a software developer who used a public or private cloud the way it should be used, you just know that Docker is a huge deal. If you didn&amp;rsquo;t, you might have trouble here but I&amp;rsquo;ll try to explain anyway.&lt;/p&gt;

&lt;p&gt;What public IaaS/PaaS services have really given us was a glimpse into the future. At the same time, they only took us half the way. With AWS etc, people have started to build resilient and scalable systems, but many wanted to take it further. Microservices are an obvious step but even cheapest and smallest VMs out there are just too powerful for that approach. If you imagine an app that&amp;rsquo;s deployed on 100+ micro instances for architectural reasons, well, that&amp;rsquo;s not pretty. We went to the cloud to reduce operational overhead, yet we found ourselves under pressure to actually increase it and to waste computing resources in the process. Containers enable reasonable isolation without overhead of using a VM. Starting a container is not really different from starting a process (in terms of both resource usage and speed!). Docker makes all that easy to use, and easy to build further automation on top of. All the missing pieces are suddenly in place. We get to:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Architecture described in code, possibly changing from version to version, deployed and scaled automatically&lt;/li&gt;
&lt;li&gt;Heterogeneous environment that doesn&amp;rsquo;t dissolve into complete mess&lt;/li&gt;
&lt;li&gt;Continuous delivery of user value with even lower risk - deployment at service level, very easy side by side deployments&lt;/li&gt;
&lt;li&gt;Modularization enabling everyone to better control technology debt, and giving the option of rewriting stuff if absolutely necessary&lt;/li&gt;
&lt;li&gt;Standardized workflow: developer machine, test, staging, production - all running the same code, just configured differently&lt;/li&gt;
&lt;li&gt;All that without locking ourselves into using single IaaS/PaaS vendor (I don&amp;rsquo;t think of it as a big deal, but some people do)&lt;/li&gt;
&lt;li&gt;With close to optimal resource usage because we can pack many containers per VM!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;What does it all mean if I&amp;rsquo;m just starting? When I was finishing my studies, early into professional career, the cheapest way to set up a server was to use bare metal machine and pay $300/mo or something like that, very often on 12-months+ contract. And these servers weren&amp;rsquo;t really that powerful, iirc it was something like dual socket single core Xeon (several generations behind!) + 1 GB of memory and small SCSI disk. You want RAID? Load balancer and more machines for better availability or to scale performance? Dedicated DB machine? Costs were going up very, very quickly. Count in operational overhead of bare metal hw and you ended up with pretty high numbers (account for the fact that back then there was no Puppet/Chef/Ansible etc - we used bash and Perl to automate operations!).&lt;/p&gt;

&lt;p&gt;Today you can get a fully featured VM for as little as $5/mo, so you can easily host replicated db + redundant web instances for $20/mo. You can scale it up when the needs arise, with provisioning within minutes. Thanks to Docker, you can use this setup to build using microservices from the very beginning, so there will be no need to go beyond these cheap VMs before you are actually resource limited. Realistically, we are talking 30-50x reduction in initial infrastructure costs. On operational side everything is also a lot easier thanks to APIs and much more mature tools. Setting up/tearing down test environments can be fully automated. If you go with AWS, for a slightly higher price you can get DB and storage services that require almost zero work on your side (for that reason AWS probably is the sweet spot when you are limited by time). What has also changed is the efficiency of our infrastructure usage - LAMP stack is pretty much dead now (except maybe for the DB part) and people moved towards things like node.js, Go, or some new JVM based stuff which bring further cost savings. Not only is the infrastructure cheaper, we can also get more from it, and all that without sacrificing application architecture. Obviously, you still have to know how to build distributed applications, but having that knowledge things are a lot easier now :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Functional programming trojan horse</title>
      <link>/2013/09/22/functional-programming-trojan-horse/</link>
      <pubDate>Sun, 22 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/09/22/functional-programming-trojan-horse/</guid>
      <description>

&lt;p&gt;All of game server code at my current company is using C++, and we are still starting new projects using existing C++ framework. I gave a presentation on our server architecture a few months ago, available &lt;a href=&#34;http://www.slideshare.net/maciejmroz/architektura-serwera-gier-online&#34;&gt;here&lt;/a&gt; (it&amp;rsquo;s in Polish, it was local event here in Kraków). After giving the presentation I was approached by a guy (sorry, don&amp;rsquo;t remember the name) who said something like: &amp;ldquo;It&amp;rsquo;s cool you did all that in C++. It&amp;rsquo;d be interesting to see you talk next year about how you rewritten the whole thing in Java :)&amp;ldquo;. I instantly answered: &amp;ldquo;Right now I&amp;rsquo;d do it with Scala and Akka&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;I wasn&amp;rsquo;t even thinking about it, it was absolutely obvious: if I were to do it from scratch, it&amp;rsquo;d do it in Scala. It felt a bit like an inception coming to the surface of my mind. It became pretty clear to me to that the only reason I am working on C++ server technology is because of the mild lockin: the benefits of rewriting server framework are smaller than gains. It suits our needs very well, programmers are familiar with it, so why change something that just works? However, it remains true that not only it would take less time to implement using Scala and Akka, but Akka is in some areas vastly better than what we did in C++.&lt;/p&gt;

&lt;h2 id=&#34;what-s-so-special-about-scala&#34;&gt;What&amp;rsquo;s so special about Scala?&lt;/h2&gt;

&lt;p&gt;I would never advocate use of programming language because of a cool name (admit it, it is cool :) ). The reason I actually decided to learn Scala is very simple: for the kind of problems I&amp;rsquo;m dealing with (complex server side systems), JVM as a platform has won. Sure, there are alternatives, but platform is much more than a language: it&amp;rsquo;s also a vm, tools, libraries and community. On these fronts, JVM is a winner by wide margin. Because I generally dislike Java for being so verbose (it&amp;rsquo;s 21st century, and we are expected to write code in simplified version of C++?), after playing for a short while with Clojure (which is awesome, just as any other Lisp dialect out there :) ), I quickly settled on Scala. The fact that functional programming fits my way of thinking about solving problems helped a lot, too :) So far I have spent about six months learning Scala, and still feel a lot like a novice. However, I know my way around it enough to have an opinion: I think it is the most important programming language created in past 10 years. Scala also is what Java should have been in the first place, but failed to ever become.&lt;/p&gt;

&lt;p&gt;Word of warning: Scala is a big language, and learning it will take a lot of effort. While on the surface it is &amp;ldquo;Java with sane syntax and traits&amp;rdquo; it is also a functional programming language. Sooner or later you are going to hear words like functor or monad. The good thing is that you can get started very quickly and learn new concepts as you go. I will not cover everything there is to know about Scala, only the parts I found to be the most important. In the end, if you wish to learn any new programming language, you&amp;rsquo;ll have to do it on your own.&lt;/p&gt;

&lt;h2 id=&#34;syntax&#34;&gt;Syntax&lt;/h2&gt;

&lt;p&gt;Over the years I have developed a fair bit of negative attitude towards languages with a lot of boilerplate. In fact I believe that longer code is the code with more bugs, regardless of programmer skill level. At the same time, I am a big fan of strong and static typing, which obviously creates a conflict. Both Java and C++ are very far from being expressive. Scala does a lot to remove boilerplate typically found in such languages, and allows the code to look much more similar to dynamic languages. You can write code like this:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;    &lt;span style=&#34;color: #66d9ef&#34;&gt;val&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;knownPermissionNames&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #a6e22e&#34;&gt;Permissions&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;values&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;map&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;_&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;toString&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This line of code produces a collection of String objects. However, collection type is never named explicitly here. The type is inferred by the compiler. Type inference saves a lot of completely unnecessary typing, but that&amp;rsquo;s not all you can see in code above. If you noticed that there&amp;rsquo;s no semicolon up there, congratulations. Most of the time, there&amp;rsquo;s no need to use it, because it also inferred by the compiler. What else is up there? Anonymous function passed to map, using shortened syntax with underscore character acting as placeholder for function argument. That&amp;rsquo;s still not all of the good stuff: in many cases you can omit parentheses on function calls, and there is no need for explicit return from function - the function value is simply the value of its last statement. In short: &lt;strong&gt;a lot&lt;/strong&gt; less typing, without sacrificing compile time type safety, and most of the time, actually improving code readability. What&amp;rsquo;s not to like? :)&lt;/p&gt;

&lt;h2 id=&#34;functional-goodness&#34;&gt;Functional goodness&lt;/h2&gt;

&lt;p&gt;Scala is not only an OO language, but also a functional one. That means functions are &amp;ldquo;first class&amp;rdquo; citizens of the language: they can be stored as values, passed around, and returned from other functions. Scala supports both partial function application and currying, which really comes in handy. You can define anonymous functions. Also functions can be nested inside one another (quite useful because nested function has access to enclosing scope). The compiler is capable of optimizing out tail recursion, which makes it nice alternative to using &amp;ldquo;while&amp;rdquo; loop (and btw: it is the only kind of loop that Scala really has, &amp;ldquo;for&amp;rdquo; keyword is not a loop!), and is just as efficient at bytecode level. Now, trying to argue functional vs OO is not my point here. Use it if you want to, or when you are ready to :) You&amp;rsquo;ll end up with code that&amp;rsquo;s loosely coupled, short, readable and maintainable. These are very good goals to have.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s time to talk about another very important concept closely tied to functional programming, which is data immutability. While immutability in Scala is not enforced, it is considered good programming style and is mostly default. Working with immutable data has a lot of advantages - there&amp;rsquo;s no real need to encapsulate state in objects, because there&amp;rsquo;s no way to mutate the state. For the same reason, there&amp;rsquo;s no need for doing any defensive copies. Once you start to think in terms of data transformation rather than mutation, programming becomes simpler: code is easier to understand and easier to reason about. Immutable data structures are thread safe by nature - you can pass them around like there&amp;rsquo;s no tomorrow. What I found very quickly when I started playing with Scala, was that it was very natural programming style to keep data and code that operates on it separate instead of tightly coupling them inside the same class (i.e. by using case class and its companion object). Scala has pretty awesome standard collection library, and most collections have mutable and immutable versions (with immutable being default). Learning to use collections effectively is probably going to take some time, but simply using map, fold and filter operations can get you very far very easily. Again, you can learn less commonly used methods on standard collections gradually (and it is absolutely worth it!).&lt;/p&gt;

&lt;p&gt;Important feature that complements immutable data is pattern matching. It may initially look like &amp;ldquo;switch on steroids&amp;rdquo; but it is an understatement. Pattern matching is one of the most powerful features of the language. Because you are passing around data structures, you can easily match on the structure or part of it, and extract what&amp;rsquo;s needed, without writing extra utility functions or doing any intrusive modifications to classes holding the data (when data is immutable, there aren&amp;rsquo;t many reasons not to have everything public by default &amp;hellip;). Simple pattern matching looks like this (code from my pet project):&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;    &lt;span style=&#34;color: #f8f8f2&#34;&gt;teamModificationResult&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;match&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;{&lt;/span&gt;
        &lt;span style=&#34;color: #66d9ef&#34;&gt;case&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;models&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;TeamModificationNone&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;userId&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;role&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;(...)&lt;/span&gt;
        &lt;span style=&#34;color: #66d9ef&#34;&gt;case&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;models&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;TeamModificationMemberAddSuccess&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;userId&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;role&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;(...)&lt;/span&gt;
        &lt;span style=&#34;color: #f92672&#34;&gt;(...)&lt;/span&gt;
    &lt;span style=&#34;color: #f92672&#34;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You can do this kind of matching on arbitratily nested data structures, and destructure exactly the needed parts. Not enough? Destructuring process is actually programmable through feature called extractors. Conceptually, you can imagine that patterns are not really some fixed compile time constructs, but your own code. If you want to pattern match on string containing JSON encoded data, you can do it if you want to. Standard Scala regular expressions are also extractors, by the way :)&lt;/p&gt;

&lt;p&gt;When talking about functional programming parts of the language, I believe it is important to mention for comprehensions. Scala ‘for’ is in fact syntactic abstraction over map, flatMap, filter and foreach methods. This is very important because it makes it possible to use for comprehensions with non-collection types. The type that implements map and flatMap methods is essentially what math people call a monad. Hence, you’ll cometimes see for comprehensions being referred to as monadic comprehensions. Worry not, while it initially is a bit mind bending, it is not rocket science :) Option[A] is an example of monad that is not a collection type. Because it has map and flatMap methods, it can be used in for comprehension. What’s important to remember is that ‘for’ in Scala is just a syntax sugar, and has nothing to do with loops!&lt;/p&gt;

&lt;h2 id=&#34;error-handling&#34;&gt;Error handling&lt;/h2&gt;

&lt;p&gt;In functional language, Java style exceptions are simply out of place. While there have been many discussions over the years about merits of using exceptions (or not), because exceptions break program control flow, they make it a lot harder to reason about program correctness.&lt;/p&gt;

&lt;p&gt;Scala does support Java exceptions but it is mostly used to interface with Java code. In functional programming world, there are better solutions.
The first very important and very commonly used thing is Option generic type. Option[T] can hold value of type T, or nothing (called None). When you return Option[T] you say “I’ll return a value of type T, but you can’t be sure it will really be there”. This may or may not be an error, sometimes not returning a valid value is entirely expected.&lt;/p&gt;

&lt;p&gt;Why not simply pass around null references? :) The answer is obvious to any programmer out there: we don’t always check for null … and our code crashes a lot because of that :)&lt;/p&gt;

&lt;p&gt;Option[T] has two interesting properties:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Option[A] can be transformed into Option[B] by using (A) =&amp;gt; B function passed to map, or (A) =&amp;gt; Option[B] function passed to flatMap. That means you can write your code as if “null case” doesn’t exist and code happy path only when doing computations. Option[T] propagates None value for you. That also means Option[A] is a monad and can be used with for comprehensions, as mentioned earlier.&lt;/li&gt;
&lt;li&gt;When you actually want to get value out of Option, you have to do it manually. You can still get an exception at this stage (if you use plain get), but typically you’ll use pattern matching (on both value and None cases) or getOrElse method. Essentially the language encourages programmer to handle the None case, instead of encouraging programmer to assume everything is great and null will never be there.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In general, using null in Scala is a bad style, there’s simply no need for it.&lt;/p&gt;

&lt;p&gt;The second similar but a bit more complex type is called Either[A,B]. As name suggests, it holds either A or B. It is very common for Either to hold value or an error (which can even be an exception object, but it is passed around, not thrown). It can be transformed in similar way as Option by using mapping functions.&lt;/p&gt;

&lt;h2 id=&#34;what-else-is-there&#34;&gt;What else is there?&lt;/h2&gt;

&lt;p&gt;A lot. Most importantly concurrency features: actors, futures, parallel collections, software transactional memory. Also libraries like scalaz or shapeless that push functionals part of Scala pretty hard. I did not talk about OO parts at all, not because I don’t consider them important, but because it’s the first thing you’ll run into (along with constructs like cake pattern) when starting to learn the language.&lt;/p&gt;

&lt;p&gt;In the title of this blog post I named Scala a ‘trojan horse’. That’s exactly what it is. While technological advancement makes writing certain classes of software easier and easier, it also pushes us towards solving problems we wouldn’t think of trying to solve 10 years ago. The biggest challenge right now is in distributed and concurrent systems. This is where we need every bit of correctness and abstraction we can get from compiler and language. This is really, really hard stuff and this is exactly where functional languages shine. However, languages like Haskell are alien to current breed of programmers who grew up writing imperative code most of their life (if not all of it). Distributed and concurrent systems are also exactly where the growth is right now (there are many trends that overlap: mobile devices, “Internet of things”, ubiquituous cloud computing, “big data” technologies etc). Scala is the bridge between old world and new one. The destination is not known (if history taught us anything, Scala will not be the last word and will be replaced by something better) but right now Scala seems to be the language best suited to face the future.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Is virtualization a failure of operating systems?</title>
      <link>/2012/12/19/is-virtualization-a-failure-of-operating-systems/</link>
      <pubDate>Wed, 19 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/12/19/is-virtualization-a-failure-of-operating-systems/</guid>
      <description>&lt;p&gt;One thing has hit me while watching of this year&amp;rsquo;s LinuxCon Europe presentations - one of reasons virtualization exists in the first place is operating system inability to properly isolate the applications from each other. Look at it this way: the role of operating systems is abstracting the physical hardware from the applications. And what is the role of hypervisor? Abstracting the hardware from the opertaing system(s) … Which makes the operating system an application running under the hypervisor, doesn&amp;rsquo;t it?&lt;/p&gt;

&lt;p&gt;Now, let&amp;rsquo;s think of it from other angle - why are we using virtualization? We are virtualizing applications, and operating system is only a required intermediary. Typical workload of virtual machine is exactly one application (in general case this is one-to-many relationship, because often single application spans multiple VMs). We do this partly to achieve good utilization of physical hardware, but also to achieve isolation at the level close to &amp;ldquo;physical box per every application&amp;rdquo;. Not as secure, but conceptually equivalent.&lt;/p&gt;

&lt;p&gt;In fact, this level of isolation is desireable on the desktop, too. VM to run untrusted USB stick? Seems like a good idea, and that&amp;rsquo;s only one of possible use cases. If we are running entire operating system just to run one application, isn&amp;rsquo;t it a waste? What can run under the hypervisor doesn&amp;rsquo;t really have to be a complete operating system. There are projects like Erlang on Xen (&lt;a href=&#34;http://erlangonxen.org&#34;&gt;erlangonxen.org&lt;/a&gt;) or Mirage that seem to skip the OS and talk straight to the hypervisor API - I am not familiar with the implementation details of these projects, but that seems to be general idea. And that makes hypervisor … an operating system. An operating system that opens up plethora of new and exciting possibilities, and one much better fit for todays world - but still an operating system.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Enter the Node.js</title>
      <link>/2012/07/07/enter-the-node-js/</link>
      <pubDate>Sat, 07 Jul 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/07/07/enter-the-node-js/</guid>
      <description>

&lt;p&gt;The title says it all, but I probably still should paint some background to this article. Imagine a system where you need very high performance, you need it yesterday, and you don&amp;rsquo;t have infinite funds to simply throw more hardware at the problem. Very important component in this system is a web server. Very simple requests, always generated by code (while system in question does not provide data to end users, you can think of AJAX - definitely there&amp;rsquo;s a similarity). So I have a webserver in question. Apache + PHP, running on a virtual machine. I quickly written a Python script that emulated the workload webserver was supposed to have (fuzzed POST requests in specific format). I did back of the envelope calculations of the performance the web server has to meet. As it turned out, Apache + PHP running on a virtual machine was at very, very small percentage of what I needed.&lt;/p&gt;

&lt;p&gt;Obvious thing I tried was to get a VM with a lot more CPU power. It indeed got me a lot more performance, but as you might have guessed already, getting the improvement I needed was hardly possible this way. So I moved the webserver to a physical box (I have these too :) ). As I quickly learned after going physical, the Python script I was using to test the webserver couldn&amp;rsquo;t truly cut it any more and was adding a lot of overhead. I gave up the idea of precisely simulating the workload, took one example request, and used the industry standard - Apache Benchmark (ab). Even before that is was obvious that Apache + PHP is not going to cut it. My initial idea for improvement was to use nginx + PHP running in FastCGI mode. It did run, and initial results were quite promising but &amp;hellip; you&amp;rsquo;ll see results below. Anyway, nginx wasn&amp;rsquo;t cutting it.&lt;/p&gt;

&lt;p&gt;I intended to take a deeper look at node.js for a long time but never really had a project that would push me far enough. This one was it. I am not a web developer, and JavaScript is hardly my language (I think in C++ but usually use Python because I am lazy). Anyway, imperative languages are mostly the same, I hacked node.js app that did what I needed. I slightly changed system design along along the way - node.js output format was JSON instead of CSV used by PHP app. Still, the apps were computationally equivalent, and it terms of I/O node.js was actually a bit more verbose. Output was pushed over the network to another service, so web app itself was not doing any disk I/O. Backend service was not the bottleneck.&lt;/p&gt;

&lt;p&gt;The benchmark was done on Core i3 540, CentOS Linux 6.2, using newest node.js, PHP 5.3.x with APC installed, newest stable nginx, Apache 2.2.x. Node app was using &amp;lsquo;cluster&amp;rsquo; module (built in) in order to use all available logical CPU cores. Nginx was using PHP via FastCGI interface, Apache was running in &amp;lsquo;prefork&amp;rsquo; mode and PHP compiled as a module. I tried to benchmark 8,32,128,512,1024, 2048, 4096 simultaneous clients on 500k requests. Machine used to run ab was using some quad core Intel CPU and CentOS Linux 5.5 and was connected to the same 1 GBit switch the web server was connected to.&lt;/p&gt;

&lt;h2 id=&#34;apache-vs-nginx&#34;&gt;Apache vs Nginx&lt;/h2&gt;

&lt;p&gt;I guess that before going in details into results that I got from node it&amp;rsquo;s good to compare Apache and nginx - there&amp;rsquo;s a lot of comparisons out there, and many of them suggest that nginx is significantly better &amp;hellip; Apache results:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;8 clients: 2250 requests/sec, 4 ms latency&lt;/li&gt;
&lt;li&gt;32 clients: 2250 requests/sec, 14 ms latency&lt;/li&gt;
&lt;li&gt;128 clients: 2100 requests/sec, 60 ms latency&lt;/li&gt;
&lt;li&gt;512 clients: 2100 requests/sec, 240 ms latency&lt;/li&gt;
&lt;li&gt;1024 clients: FAILED&lt;/li&gt;
&lt;li&gt;2048 clients: &amp;mdash;&amp;mdash;-&lt;/li&gt;
&lt;li&gt;4096 clients: &amp;mdash;&amp;mdash;-&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Apache had mostly flat performance, going slightly down from 32 to 128 clients. At 1024 clients it simply stopped accepting connections. Still, if the request completed, it completed without error, and up to 512 simultaneous clients request latency was going up linearly with number of clients. Honestly, these are not bad results and I&amp;rsquo;d be fine with them if my target wasn&amp;rsquo;t at 5k requests per second. Nginx results:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;8 clients: 2250 rps, 4 ms latency&lt;/li&gt;
&lt;li&gt;32 clients: 2350 rps, 14 ms latency&lt;/li&gt;
&lt;li&gt;128 clients: 2350 rps, 55 ms latency&lt;/li&gt;
&lt;li&gt;512 clients: 2100 rps, 241 ms latency (~500 failed!)&lt;/li&gt;
&lt;li&gt;1024 clients: 1900 rps, 540 ms latency (~3650 failed!)&lt;/li&gt;
&lt;li&gt;2048 clients: FAILED (completed but error rate 80%+)&lt;/li&gt;
&lt;li&gt;4096 clients: &amp;mdash;&amp;mdash;-&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Nginx was never vastly faster than Apache. Still, at realistic workloads it indeed was slightly faster. What happened at higher concurrency levels was interesting. At 512 clients roughly 500 requests failed (completed with HTTP code other than 2xx) which is about 1 in 1000. The error rate went up even more at 1024 clients. The breakdown happened at 2048 clients - the benchmark did complete, but with more than 80% of requests ending in non-2xx code (I suppose it was 500 Internal server Error or something like that &amp;hellip;). To sum things up: the way nginx performance degrades with concurrency is different from Apache, and on the extreme end nginx was actually slower. Apache and nginx, while different, were still in the same performance league. I still needed 5000 requests per second and it was time to try out node.js.&lt;/p&gt;

&lt;h2 id=&#34;welcome-the-king&#34;&gt;Welcome the king&lt;/h2&gt;

&lt;p&gt;Node.js results:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;8 clients: 4700 rps, 2 ms latency&lt;/li&gt;
&lt;li&gt;32 clients: 6900 rps, 5 ms latency&lt;/li&gt;
&lt;li&gt;128 clients: 7200 rps, 18 ms latency&lt;/li&gt;
&lt;li&gt;512 clients: 7200 rps, 70 ms latency&lt;/li&gt;
&lt;li&gt;1024 clients: 7150 rps, 143 ms latency&lt;/li&gt;
&lt;li&gt;2048 clients: 7100 rps, 288 ms latency&lt;/li&gt;
&lt;li&gt;4096 clients: 6900 rps, 590 ms latency&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Shocking, isn&amp;rsquo;t it? Node was running in circles around traditional web servers! Its peak performance was not only at higher concurrency level, but the performance drop with more clients was only slight, instead of completely dying. It was able to complete the benchmark up to 4096 simultaneous clients, with 0 (zero!) errors (even if latency was high) &amp;hellip; For me it&amp;rsquo;s almost end of the road - I got more performance than I actually needed. Now it&amp;rsquo;s time to polish the code, write documentation etc - and then move to other parts of the system.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;d love to repeat the benchmark on faster CPU some day (the i3 used was all I had in the office at the moment) - it seems that all servers in question would benefit a lot from more CPU power. Also, redoing the benchmarks on faster CPU with more physical cores might reveal some other limitations. After this experience, node is definitely going to be important part of my toolbox - it seems perfectly suited for many of the things I am struggling with at work. Still, it is unlikely to ever replace traditional webservers across the stack.&lt;/p&gt;

&lt;p&gt;Something to think about: HTTP is actually very simple protocol. We made it complicated, and mainstream webservers moved along to support all the bells and whistles. What we have right now is like showing up on a car race with expensive limousine: it may have tons of great gizmos and might be a better all-rounder, but on a race track it is crushed by cars that were built to race.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>